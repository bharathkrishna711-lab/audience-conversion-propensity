{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f41066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "908c7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datset\n",
    "df=pd.read_excel(r\"C:\\Users\\bhara\\OneDrive\\Desktop\\INTERVIEW PREPS\\ML PROJECT 1\\Audience-Conversion-Propensity\\notebooks\\data\\raw\\cohort_conversion_dataset.xlsx\")\n",
    "\n",
    "# Fixing hidden spaces from Excel exports \n",
    "df.columns = df.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf582537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean        0.127675\n",
       "std         0.061288\n",
       "min         0.021800\n",
       "25%         0.076200\n",
       "50%         0.123050\n",
       "75%         0.172500\n",
       "max         0.313500\n",
       "Name: conversion_rate_7d, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"conversion_rate_7d\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8e7e5",
   "metadata": {},
   "source": [
    "The data set contains only converted people's data. So doing a binary classificarion is impossble. \n",
    "\n",
    "Taking a new approach of finding the users with high conv rate \n",
    "This creates:\n",
    "\n",
    "high-conversion users → 1\n",
    "\n",
    "low-conversion users → 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04732ce",
   "metadata": {},
   "source": [
    "Trying to find a good threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eaff539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8916)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"converted_7d\"] = (df[\"conversion_rate_7d\"] >= 0.05).astype(int)\n",
    "df[\"converted_7d\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5dbb25",
   "metadata": {},
   "source": [
    "0.5 as conversion rate wont work as the data is still skewed with ~90% of positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a6ebc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    0.123050\n",
       "0.70    0.161400\n",
       "0.80    0.183520\n",
       "0.90    0.213510\n",
       "0.95    0.235705\n",
       "0.98    0.257504\n",
       "Name: conversion_rate_7d, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"conversion_rate_7d\"].quantile([0.5, 0.7, 0.8, 0.9, 0.95, 0.98])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc9b6a0",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Half the users have conversion rate ≤ 12.3%\n",
    "\n",
    "Top 20% start at 18.4%\n",
    "\n",
    "Top 10% start at 21.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a234fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = df[\"conversion_rate_7d\"].quantile(0.80)\n",
    "\n",
    "df[\"converted_7d\"] = (df[\"conversion_rate_7d\"] >= threshold).astype(int)\n",
    "\n",
    "df[\"converted_7d\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c07ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clicks_per_user\"] = df[\"clicks_7d\"] / (df[\"users_exposed\"] + 1)\n",
    "df[\"add_to_cart_rate\"] = df[\"add_to_cart_7d\"] / (df[\"users_exposed\"] + 1)\n",
    "df[\"frequency_recency_ratio\"] = df[\"avg_frequency_7d\"] / (df[\"recency_hours\"] + 1)\n",
    "df[\"seasonal_engagement\"] = df[\"add_to_cart_rate\"] * df[\"seasonality_index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5eabbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"converted_7d\"\n",
    "\n",
    "categorical_features = [\"geo\", \"device\", \"audience_segment\", \"product_category\"]\n",
    "\n",
    "numeric_features = [\n",
    "    \"users_exposed\", \"impressions_7d\", \"avg_frequency_7d\", \"recency_hours\",\n",
    "    \"clicks_7d\", \"ctr_7d\", \"site_visits_7d\", \"product_views_7d\",\n",
    "    \"add_to_cart_7d\", \"avg_session_time_sec\",\n",
    "    \"prev_conv_rate_28d\",      # history feature\n",
    "    \"seasonality_index\",\n",
    "    # engineered\n",
    "    \"clicks_per_user\", \"add_to_cart_rate\", \"frequency_recency_ratio\", \"seasonal_engagement\"\n",
    "]\n",
    "\n",
    "FEATURES = numeric_features + categorical_features\n",
    "\n",
    "numeric_no_hist = [c for c in numeric_features if c != \"prev_conv_rate_28d\"]\n",
    "FEATURES_NO_HIST = numeric_no_hist + categorical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6940cd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positive rate: 0.2035\n",
      "Test positive rate : 0.186\n"
     ]
    }
   ],
   "source": [
    "X = df[FEATURES].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Train positive rate:\", y_train.mean())\n",
    "print(\"Test positive rate :\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fb66c",
   "metadata": {},
   "source": [
    "### Train–Test Class Distribution Check\n",
    "\n",
    "After using a time-based train–test split, the proportion of converters stays fairly consistent across both datasets:\n",
    "\n",
    "- **Training set:** ~20.35% converters  \n",
    "- **Test set:** ~18.6% converters  \n",
    "\n",
    "This suggests that the split did not introduce any major class imbalance or leakage issues. Since the conversion rates are similar in both sets, the evaluation on the test data should reasonably reflect how the model would perform on future, unseen users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77e99739",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "049ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_prob, k):\n",
    "    topk = np.argsort(y_prob)[::-1][:k]\n",
    "    return y_true.iloc[topk].mean()\n",
    "\n",
    "def recall_at_k(y_true, y_prob, k):\n",
    "    topk = np.argsort(y_prob)[::-1][:k]\n",
    "    return y_true.iloc[topk].sum() / max(1, y_true.sum())\n",
    "\n",
    "def evaluate_probs(y_true, y_prob, frac=0.10):\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    pr = average_precision_score(y_true, y_prob)\n",
    "    k = max(1, int(frac * len(y_true)))\n",
    "    p_at_k = precision_at_k(y_true, y_prob, k)\n",
    "    r_at_k = recall_at_k(y_true, y_prob, k)\n",
    "    return {\"ROC_AUC\": roc, \"PR_AUC\": pr, \"k\": k, \"Precision@k\": p_at_k, \"Recall@k\": r_at_k}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db210a3a",
   "metadata": {},
   "source": [
    "Baseline logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b88540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhara\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.5476935880161686,\n",
       " 'PR_AUC': 0.2277118955442796,\n",
       " 'k': 100,\n",
       " 'Precision@k': np.float64(0.27),\n",
       " 'Recall@k': np.float64(0.14516129032258066)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "logit_probs = logit.predict_proba(X_test)[:,1]\n",
    "\n",
    "baseline_metrics = evaluate_probs(y_test, logit_probs)\n",
    "baseline_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e25bd",
   "metadata": {},
   "source": [
    "Since the data was on different scales,ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e421c1",
   "metadata": {},
   "source": [
    "Standardize numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c785a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1376d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e86d9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.9325843438746665,\n",
       " 'PR_AUC': 0.7436228890995693,\n",
       " 'k': 100,\n",
       " 'Precision@k': np.float64(0.76),\n",
       " 'Recall@k': np.float64(0.40860215053763443)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=3000))\n",
    "])\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "logit_probs = logit.predict_proba(X_test)[:,1]\n",
    "baseline_metrics = evaluate_probs(y_test, logit_probs)\n",
    "baseline_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f3116",
   "metadata": {},
   "source": [
    "\n",
    "Precision@100 = 76%\t\n",
    "\n",
    "means 76 of the top 100 segments will actually convert\n",
    "\n",
    "\n",
    "Recall@100 = 41%\t\n",
    "\n",
    "means we  capture 41% of all converting cohorts\n",
    "\n",
    "ROC-AUC = 0.93\tModel separates converters vs non-converters extremely well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6baf48b",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e03b722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.9200879765395894,\n",
       " 'PR_AUC': 0.6341793912017228,\n",
       " 'k': 100,\n",
       " 'Precision@k': np.float64(0.7),\n",
       " 'Recall@k': np.float64(0.3763440860215054)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        min_samples_leaf=50,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_probs = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "evaluate_probs(y_test, rf_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e213b",
   "metadata": {},
   "source": [
    "XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f3b0896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.9224194869356159,\n",
       " 'PR_AUC': 0.6785540998875638,\n",
       " 'k': 100,\n",
       " 'Precision@k': np.float64(0.71),\n",
       " 'Recall@k': np.float64(0.3817204301075269)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_probs = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "evaluate_probs(y_test, xgb_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187edff3",
   "metadata": {},
   "source": [
    "extracting feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71842fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num__prev_conv_rate_28d</td>\n",
       "      <td>3.199815</td>\n",
       "      <td>3.199815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num__seasonality_index</td>\n",
       "      <td>0.631607</td>\n",
       "      <td>0.631607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__impressions_7d</td>\n",
       "      <td>0.589418</td>\n",
       "      <td>0.589418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>num__clicks_per_user</td>\n",
       "      <td>0.422465</td>\n",
       "      <td>0.422465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__avg_frequency_7d</td>\n",
       "      <td>-0.381492</td>\n",
       "      <td>0.381492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__clicks_7d</td>\n",
       "      <td>-0.374308</td>\n",
       "      <td>0.374308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num__add_to_cart_7d</td>\n",
       "      <td>0.315265</td>\n",
       "      <td>0.315265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__users_exposed</td>\n",
       "      <td>-0.243566</td>\n",
       "      <td>0.243566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num__seasonal_engagement</td>\n",
       "      <td>-0.216890</td>\n",
       "      <td>0.216890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cat__audience_segment_Book Lovers</td>\n",
       "      <td>0.213859</td>\n",
       "      <td>0.213859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num__product_views_7d</td>\n",
       "      <td>-0.175923</td>\n",
       "      <td>0.175923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cat__audience_segment_Casual Browsers</td>\n",
       "      <td>-0.160983</td>\n",
       "      <td>0.160983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cat__geo_US</td>\n",
       "      <td>-0.138021</td>\n",
       "      <td>0.138021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num__site_visits_7d</td>\n",
       "      <td>-0.084959</td>\n",
       "      <td>0.084959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cat__geo_IN</td>\n",
       "      <td>0.084527</td>\n",
       "      <td>0.084527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num__avg_session_time_sec</td>\n",
       "      <td>-0.082987</td>\n",
       "      <td>0.082987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cat__product_category_Beauty</td>\n",
       "      <td>-0.081079</td>\n",
       "      <td>0.081079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cat__audience_segment_Beauty Buyers</td>\n",
       "      <td>-0.081079</td>\n",
       "      <td>0.081079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cat__audience_segment_New Parents</td>\n",
       "      <td>-0.076495</td>\n",
       "      <td>0.076495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cat__product_category_Baby Care</td>\n",
       "      <td>-0.076495</td>\n",
       "      <td>0.076495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  feature      coef  abs_coef\n",
       "10                num__prev_conv_rate_28d  3.199815  3.199815\n",
       "11                 num__seasonality_index  0.631607  0.631607\n",
       "1                     num__impressions_7d  0.589418  0.589418\n",
       "12                   num__clicks_per_user  0.422465  0.422465\n",
       "2                   num__avg_frequency_7d -0.381492  0.381492\n",
       "4                          num__clicks_7d -0.374308  0.374308\n",
       "8                     num__add_to_cart_7d  0.315265  0.315265\n",
       "0                      num__users_exposed -0.243566  0.243566\n",
       "15               num__seasonal_engagement -0.216890  0.216890\n",
       "22      cat__audience_segment_Book Lovers  0.213859  0.213859\n",
       "7                   num__product_views_7d -0.175923  0.175923\n",
       "23  cat__audience_segment_Casual Browsers -0.160983  0.160983\n",
       "18                            cat__geo_US -0.138021  0.138021\n",
       "6                     num__site_visits_7d -0.084959  0.084959\n",
       "16                            cat__geo_IN  0.084527  0.084527\n",
       "9               num__avg_session_time_sec -0.082987  0.082987\n",
       "30           cat__product_category_Beauty -0.081079  0.081079\n",
       "21    cat__audience_segment_Beauty Buyers -0.081079  0.081079\n",
       "27      cat__audience_segment_New Parents -0.076495  0.076495\n",
       "29        cat__product_category_Baby Care -0.076495  0.076495"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = logit  \n",
    "\n",
    "feature_names = best_model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "coefs = best_model.named_steps[\"model\"].coef_[0]\n",
    "\n",
    "imp = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coef\": coefs,\n",
    "    \"abs_coef\": np.abs(coefs)\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "imp.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab9911",
   "metadata": {},
   "source": [
    "Insights from feature importance output\n",
    "\n",
    "num_prev_conv_rate_28d → coefficient = 3.20\n",
    "\n",
    "\n",
    "A user who converted in the last 28 days is dramatically more likely to convert again.Retargeting beats cold targeting.\n",
    "\n",
    "seasonality_index → +0.63\n",
    "\n",
    "\n",
    "When product demand is high (holiday, sale week, seasonal spike), everyone converts more easily.\n",
    "\n",
    "clicks_per_user → +0.42  \n",
    "impressions_7d → +0.59  \n",
    "clicks_7d → +0.37  \n",
    "add_to_cart_7d → +0.31\n",
    "\n",
    "\n",
    "People who actively interact with ads and site are much more likely to convert.\n",
    "\n",
    "\n",
    "avg_frequency_7d → -0.38\n",
    "\n",
    "Showing too many ads hurts conversion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e138fdb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
